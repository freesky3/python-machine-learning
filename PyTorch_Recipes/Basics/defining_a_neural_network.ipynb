{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freesky3/python-machine-learning/blob/main/PyTorch_Recipes/Basics/defining_a_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91FJkotlhW2j"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lYgel3jhW2m"
      },
      "source": [
        "Defining a Neural Network in PyTorch\n",
        "====================================\n",
        "\n",
        "Deep learning uses artificial neural networks (models), which are\n",
        "computing systems that are composed of many layers of interconnected\n",
        "units. By passing data through these interconnected units, a neural\n",
        "network is able to learn how to approximate the computations required to\n",
        "transform inputs into outputs. In PyTorch, neural networks can be\n",
        "constructed using the `torch.nn` package.\n",
        "\n",
        "Introduction\n",
        "------------\n",
        "\n",
        "PyTorch provides the elegantly designed modules and classes, including\n",
        "`torch.nn`, to help you create and train neural networks. An `nn.Module`\n",
        "contains layers, and a method `forward(input)` that returns the\n",
        "`output`.\n",
        "\n",
        "In this recipe, we will use `torch.nn` to define a neural network\n",
        "intended for the [MNIST\n",
        "dataset](hhttps://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST).\n",
        "\n",
        "Setup\n",
        "-----\n",
        "\n",
        "Before we begin, we need to install `torch` if it isn't already\n",
        "available.\n",
        "\n",
        "    pip install torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srvYqS-whW2o"
      },
      "source": [
        "Steps\n",
        "=====\n",
        "\n",
        "1.  Import all necessary libraries for loading our data\n",
        "2.  Define and initialize the neural network\n",
        "3.  Specify how data will pass through your model\n",
        "4.  \\[Optional\\] Pass data through your model to test\n",
        "\n",
        "1. Import necessary libraries for loading our data\n",
        "--------------------------------------------------\n",
        "\n",
        "For this recipe, we will use `torch` and its subsidiaries `torch.nn` and\n",
        "`torch.nn.functional`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_cfNzKGWhW2p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeC3Jv1ChW2q"
      },
      "source": [
        "2. Define and initialize the neural network\n",
        "===========================================\n",
        "\n",
        "Our network will recognize images. We will use a process built into\n",
        "PyTorch called convolution. Convolution adds each element of an image to\n",
        "its local neighbors, weighted by a kernel, or a small matrix, that helps\n",
        "us extract certain features (like edge detection, sharpness, blurriness,\n",
        "etc.) from the input image.\n",
        "\n",
        "There are two requirements for defining the `Net` class of your model.\n",
        "The first is writing an \\_\\_init\\_\\_ function that references\n",
        "`nn.Module`. This function is where you define the fully connected\n",
        "layers in your neural network.\n",
        "\n",
        "Using convolution, we will define our model to take 1 input image\n",
        "channel, and output match our target of 10 labels representing numbers 0\n",
        "through 9. This algorithm is yours to create, we will follow a standard\n",
        "MNIST algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KbPBlV3OhW2r",
        "outputId": "b0b670e6-7d1c-4ca2-88a2-30a3e5aa5b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "\n",
        "      # First 2D convolutional layer, taking in 1 input channel (image),\n",
        "      # outputting 32 convolutional features, with a square kernel size of 3\n",
        "      self.conv1 = nn.Conv2d(1, 32, 3, 1) # 1是卷积步长stride\n",
        "      # Second 2D convolutional layer, taking in the 32 input layers,\n",
        "      # outputting 64 convolutional features, with a square kernel size of 3\n",
        "      self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "\n",
        "      # Designed to ensure that adjacent pixels are either all 0s or all active\n",
        "      # with an input probability\n",
        "      # Dropout 会随机将输入张量的某些通道（channel）置为 0。括号里是置为零的概率\n",
        "      self.dropout1 = nn.Dropout2d(0.25)\n",
        "      self.dropout2 = nn.Dropout2d(0.5)\n",
        "\n",
        "      # First fully connected layer\n",
        "      self.fc1 = nn.Linear(9216, 128)\n",
        "      # Second fully connected layer that outputs our 10 labels\n",
        "      self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "my_nn = Net()\n",
        "print(my_nn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smlmmciUhW2s"
      },
      "source": [
        "We have finished defining our neural network, now we have to define how\n",
        "our data will pass through it.\n",
        "\n",
        "3. Specify how data will pass through your model\n",
        "================================================\n",
        "\n",
        "When you use PyTorch to build a model, you just have to define the\n",
        "`forward` function, that will pass the data into the computation graph\n",
        "(i.e. our neural network). This will represent our feed-forward\n",
        "algorithm.\n",
        "\n",
        "You can use any of the Tensor operations in the `forward` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XBpwxcl1hW2s"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "      self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "      self.dropout1 = nn.Dropout2d(0.25)\n",
        "      self.dropout2 = nn.Dropout2d(0.5)\n",
        "      self.fc1 = nn.Linear(9216, 128)\n",
        "      self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    # x represents our data\n",
        "    def forward(self, x):\n",
        "      # Pass data through conv1\n",
        "      x = self.conv1(x) # 1*32*26*26\n",
        "      # Use the rectified-linear activation function over x\n",
        "      x = F.relu(x) # 1*64*24*24\n",
        "\n",
        "      x = self.conv2(x)\n",
        "      x = F.relu(x)\n",
        "\n",
        "      # Run max pooling over x\n",
        "      x = F.max_pool2d(x, 2) # 1*64*12*12 = 9216\n",
        "      # Pass data through dropout1\n",
        "      x = self.dropout1(x)\n",
        "      # Flatten x with start_dim=1\n",
        "      x = torch.flatten(x, 1)\n",
        "      # Pass data through ``fc1``\n",
        "      x = self.fc1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.dropout2(x)\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      # Apply softmax to x\n",
        "      output = F.log_softmax(x, dim=1)\n",
        "      return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO97jT-whW2t"
      },
      "source": [
        "4. \\[Optional\\] Pass data through your model to test\n",
        "====================================================\n",
        "\n",
        "To ensure we receive our desired output, let's test our model by passing\n",
        "some random data through it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dgbiN97vhW2t",
        "outputId": "61a89452-7ca1-4c0c-b307-2c86e3459402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-2.2968934 -2.2163343 -2.2288694 -2.3337562 -2.2643187 -2.4268255\n",
            "  -2.3595994 -2.2541287 -2.3362994 -2.3277502]]\n",
            "[[0.1005708  0.10900796 0.10765007 0.09693097 0.1039008  0.08831675\n",
            "  0.09445806 0.10496496 0.09668477 0.09751489]]\n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Equates to one random 28x28 image\n",
        "random_data = torch.rand((1, 1, 28, 28)) # 1个样本，1个通道，28高，28宽\n",
        "\n",
        "img = random_data.squeeze()\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "\n",
        "my_nn = Net()\n",
        "result = my_nn(random_data)\n",
        "result = result.detach().numpy()\n",
        "print (result)\n",
        "print(np.exp(result))\n",
        "print(np.exp(result).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqy3ON2ThW2t"
      },
      "source": [
        "Each number in this resulting tensor equates to the prediction of the\n",
        "label the random tensor is associated to.\n",
        "\n",
        "Congratulations! You have successfully defined a neural network in\n",
        "PyTorch.\n",
        "\n",
        "Learn More\n",
        "==========\n",
        "\n",
        "Take a look at these other recipes to continue your learning:\n",
        "\n",
        "-   [What is a state\\_dict in\n",
        "    PyTorch](https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html)\n",
        "-   [Saving and loading models for inference in\n",
        "    PyTorch](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_models_for_inference.html)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}